{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkzUn-nNbX1c",
        "outputId": "09984921-9997-4adc-ed4d-c21ccdd06f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting polyline\n",
            "  Downloading polyline-2.0.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Downloading polyline-2.0.2-py3-none-any.whl (6.0 kB)\n",
            "Installing collected packages: polyline\n",
            "Successfully installed polyline-2.0.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install polyline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH0ICuxBbj3B",
        "outputId": "4b45e39a-83c7-48e6-d0ef-52a900176b06"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[WinError 126] The specified module could not be found. Error loading \"c:\\Users\\Mansi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstrategy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maggregate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aggregate, weighted_loss_avg\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Mansi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
            "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"c:\\Users\\Mansi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import lzma\n",
        "import flwr as fl\n",
        "import os\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.common import Metrics\n",
        "import polyline  # Polyline encoding library\n",
        "from polyline import decode\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "from typing import Callable, Union\n",
        "\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "import time\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")\n",
        "\n",
        "\n",
        "NUM_CLIENTS = 10\n",
        "\n",
        "\n",
        "def load_datasets(num_clients: int):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, ), (0.5, ))\n",
        "    ])\n",
        "    trainset = MNIST(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = MNIST(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    partition_size = len(trainset) // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
        "    testloader = DataLoader(testset, batch_size=32)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # Adjusted input size\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)  # Adjusted output dimension\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "# Polyline encoding for model parameters\n",
        "def encode_parameters(params):\n",
        "    flat_params = np.concatenate([p.flatten() for p in params])\n",
        "    int_params = (flat_params * 1e6).astype(int)\n",
        "    encoded = polyline.encode([(v, 0) for v in int_params])\n",
        "\n",
        "    # Log the encoded data for debugging\n",
        "    print(\"Encoded Parameters:\", encoded)\n",
        "    return encoded\n",
        "    \n",
        "def decode_parameters(encoded, shapes):\n",
        "    decoded = polyline.decode(encoded)\n",
        "    deltas = np.array([v[0] for v in decoded])\n",
        "    int_params = np.cumsum(deltas) / 1e6  # Reverse scaling\n",
        "    split_indices = np.cumsum([np.prod(shape) for shape in shapes])[:-1]\n",
        "    param_tensors = [torch.tensor(arr.reshape(shape)) for arr, shape in zip(np.split(int_params, split_indices), shapes)]\n",
        "    return param_tensors\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self,config):\n",
        "      params = [p.detach().cpu().numpy() for p in self.model.parameters()]\n",
        "      encoded = encode_parameters(params)\n",
        "      return [encoded]  # Wrap it in a list\n",
        "\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "      encoded = parameters[0]  # Extract first element if passed as list\n",
        "      shapes = [p.shape for p in self.model.parameters()]\n",
        "      decoded_params = decode_parameters(encoded, shapes)\n",
        "      for param, new_param in zip(self.model.parameters(), decoded_params):\n",
        "          param.data = new_param.float()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        num_labels = 0\n",
        "        for _, labels in self.trainloader:\n",
        "            num_labels += len(labels)\n",
        "        data_label_ratio = num_labels / len(self.trainloader.dataset)\n",
        "\n",
        "        # Add timestamp and data_label_ratio to metrics\n",
        "        metrics = {\"timestamp\": time.time(), \"data_label_ratio\": data_label_ratio}\n",
        "\n",
        "        return get_parameters(self.net), len(self.trainloader.dataset), metrics\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "params = get_parameters(Net())\n",
        "\n",
        "def test_with_metrics(model, dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "        recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "\n",
        "    return total_loss, accuracy, precision, recall\n",
        "\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    start_time = time.time()  # Record start time\n",
        "    net = Net().to(DEVICE)\n",
        "    valloader = valloaders[0]\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
        "    loss, accuracy, precision, recall = test_with_metrics(net, valloader)\n",
        "    end_time = time.time()  # Record end time\n",
        "    round_time = end_time - start_time  # Calculate round time\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy} / precision {precision} / recall {recall}\")\n",
        "    print(f\"Time taken for round {server_round}: {round_time} seconds\")\n",
        "    return loss, {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "\n",
        "class FceFed(FedAvg):\n",
        "    def __init__(\n",
        "        self,\n",
        "        fraction_fit: float = 0.3,\n",
        "        fraction_evaluate: float = 0.3, #Sample 50% of available clients for evaluation\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 1, #Allow evaluation with as few as 1 client\n",
        "        min_available_clients: int = 2,\n",
        "\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.fraction_fit = fraction_fit\n",
        "        self.fraction_evaluate = fraction_evaluate\n",
        "        self.min_fit_clients = min_fit_clients\n",
        "        self.min_evaluate_clients = min_evaluate_clients\n",
        "        self.min_available_clients = min_available_clients\n",
        "        self.evaluate_fn = evaluate\n",
        "        self.initial_lr = 0.001\n",
        "        self.mu = 0.1\n",
        "        self.decay_factor = 0.01\n",
        "    def __repr__(self) -> str:\n",
        "        return \"FedCfe\"\n",
        "\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        \"\"\"Initialize global model parameters.\"\"\"\n",
        "        net = Net()\n",
        "        ndarrays = get_parameters(net)\n",
        "        return fl.common.ndarrays_to_parameters(ndarrays)\n",
        "\n",
        "\n",
        "    def aggregate_fit(self, server_round, results, failures):\n",
        "        current_timestamp = time.time()\n",
        "        weights_results = []\n",
        "        for client, fit_res in results:\n",
        "            parameters = parameters_to_ndarrays(fit_res.parameters)\n",
        "            client_timestamp = fit_res.metrics[\"timestamp\"]\n",
        "            staleness = current_timestamp - client_timestamp\n",
        "\n",
        "            eta_k = self.initial_lr * np.exp(-self.decay_factor * staleness)\n",
        "            fairness_factor = max(0, 1 - self.mu * staleness)\n",
        "            data_ratio = fit_res.metrics[\"data_label_ratio\"]\n",
        "            client_weight = eta_k * data_ratio * fairness_factor\n",
        "\n",
        "\n",
        "        weights_results = [\n",
        "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "            for _, fit_res in results\n",
        "        ]\n",
        "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
        "        metrics_aggregated = {}\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=200),  \n",
        "    strategy=FceFed(),\n",
        "    client_resources=client_resources,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jykQULnpKYN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
